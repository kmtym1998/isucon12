# リバースプロキシの利用

<img width="680" alt="image" src="https://user-images.githubusercontent.com/54347899/178128027-3ac8d596-1ddd-459d-8f80-9bd7a11c026f.png">

- アプリケーションサーバに分散してリクエストを送ることで、大量のリクエスト・レスポンスをさばける
- アプリケーションサーバを水平スケーリングしてリバースプロキシすると 1 台あたりの負荷を減らせる
- コンテンツのキャッシュや HTTPS 通信の終端でパフォーマンス上有利に
- HTTP ヘッダの書き換え、IP 制限、ロギングなど

---

<img width="723" alt="image" src="https://user-images.githubusercontent.com/54347899/178128266-b7d0f015-dd53-47ce-b01b-e39d1f38a317.png">

- マルチプロセス・シングルスレッドだと、クライアントが 1 万超えたあたりでパフォーマンスが急落 (C10K 問題)
  - スレッドとプロセスについて:
    - https://webpia.jp/thread_process/
    - https://milestone-of-se.nesuke.com/sv-basic/architecture/cpu
- goroutine。軽量なスレッド
- Go のランタイムがプログラム起動時に CPU のコア数分のスレッドを生成する
- 並列化はアプリケーションコードを複雑化させるので、非効率
  - nginx などのリバースプロキシをアプリケーションの前段に置く
  - nginx もマルチプロセス・シングルスレッドで動くが、C10K 問題には「イベント駆動」というアプローチで解決
  - 画像・CSS・JS などの静的ファイルの配信はリバースプロキシからやればいい

---

- nginx は設定ファイルを書くことでアップストリームにリクエストを転送したり、直接静的ファイルを配信できる
  - 設定ファイルには簡単なロジックなら書ける
    - lua-nginx-module, ngx-mruby みたいなものがあるらしい
- nginx の version は Mainline と Stable がある。production 環境では Stable を使おう
  - AMI (Amazon Machine Image): 仮想マシンの構成を記録したテンプレート
  - Vagrant: AMI と似たような感じ。仮想マシンのテンプレートを覚えておくもの

```conf
server {
  # HTTP 通信を行うため
  listen 80;

  # リクエストボディの許容サイズ。画像ファイルなど大きなファイルを扱う場合は大きくする
  client_max_body_size 10m;

  # 公開するディレクトリを指定。このディレクトリのパスが URL のパスにそのままマッピングされる
  root /home/isucon/private_isu/webapp/public/;

  # 静的ファイルの配信を nginx 経由で行う
  location /css/ {
    root /home/isucon/private_isu/webapp/public/;

    # expire の設定をここでする。詳しくは知らない
    expires 1d;
  }
  location /js/ {
    root /home/isucon/private_isu/webapp/public/;
  }

  location / {
    # アップストリームサーバに送るリクエストヘッダ
    # デフォルトでは Host は nginx がアップストリームサーバにリクエストを送る前に proxy_pass で指定したホスト名に書き換られる。
    # もともとクライアントが送った Host を維持したいときはこの設定を入れる。頻出。
    proxy_set_header Host $host;

    # だいじな設定。nginx をリバースプロキシとするアップストリームサーバを指定する。
    proxy_pass http://localhost:8080;
  }
}
```

---

- nginx のアーキテクチャ
- マスタープロセスとワーカープロセス
- 各ワーカープロセスがリクエスト・レスポンス処理をイベント駆動で並行に実行する
- 処理の高速化のため、多重 I/O やノンブロッキング I/O を採用
  - ノンブロッキング I/O
    - 書き込むデータの到着、書き込みが完了するまでの待ち時間のこと
    - ブロッキングをなくすこともできる = ノンブロッキング
    - Linux だとファイルを open する際にフラグを設定したり、C だとグローバル変数の値を設定したり
  - 多重 I/O
    - 何言ってるかわからん
- ↑ のために C10K が nginx だと起こらない
- nginx はスレッドを利用していないので、1 つのワーカープロセスが使用できる CPU は 1 コアだけ
- ワーカープロセスを複数起動することが一般的
- ワーカープロセスの数は `worker_processes` という設定項目で変えられる。デフォルトでは 1
- auto にすると CPU のコア数を自動で指定できる

---

- gzip
  - レスポンスを圧縮するのに使う
  - HTTP クライアントが対応していれば OK
  - 対応しているクライアントのリクエストヘッダに `Accept-Encoding: gzip` が含まれている
  - ブラウザは必ず対応している
  - 概ね 1/5 程度になる
  - 不安定なネットワーク環境にいる人に対してのパフォーマンス向上
  - ネットワークコストの削減による金銭的メリット
- gzip をどう使うの

```conf
# gzip の有効化
gzip on;

# gzip する MIME タイプ
# jpeg や png は それ以上圧縮できない
# text/html はデフォルトで指定されてるからそれ以外を指定
gzip_types text/css text/javascript application/javascript application/x-javascript application/json;

# 小さいレスポンスボディを gzip するとかえって大きくなる可能性。
# デフォルトが 20 だけど、それだと小さすぎるから 1k、またはそれ以上が推奨される
gzip_min_length 1k;
```

- ビルド時にモジュールを有効にすると使える(?)機能
  - ngx_http_gzip_static_module
    - gzip した静的ファイルを nginx から配信できる
    - リクエストのたびに圧縮しなくていいから CPU 使用を抑えられる
    - Google 製の Zopfli は gzip ファイルの生成ツールの一つ
      - 圧縮率が高く、よりレスポンスサイズを下げられる
      - ただ圧縮処理時間が長い
      - 配信用に gzip を作るだけなら採用もあり
  - ngx_http_gunzip_module
    - gzip に対応していないクライアントへレスポンスするときに gzip を展開してくれる
    - サーバ上には gzip をおいておけば、このモジュールが勝手に展開してくれる
    - nginx の CPU リソースを使うが、gzip に対応していないクライアントはほぼないので問題になるケースは殆どない
- 圧縮レベル: どの程度時間をかけて圧縮するか
  - 圧縮レベルが高いほど圧縮に時間がかかるが転送量は少なくなる
  - Zlib (nginx などが gzip 圧縮に使うライブラリ) のデフォルト圧縮レベルは 6 (1~9)
- gzip 圧縮をどこで行うかも大事

<img width="632" alt="image" src="https://user-images.githubusercontent.com/54347899/178133931-36d9d1f3-08bf-4d2a-8445-6ed4579fa7cc.png">

- APP サーバでも gzip 圧縮をしたほうがいい
  - APP サーバ上で gzip をすることを念頭に台数・構成を考えたほうがいい
- ネットワークコストはパフォーマンス的にも金銭的にも高く、ボトルネックになりやすい
  - レスポンスが 1/5 になるんだぜ
  - gzip してなかったらネットワーク帯域使用量が 5 倍になると思ったらやばい
- Brotli
  - gzip でもない圧縮アルゴリズム
  - 圧縮アルゴリズムが効率的
  - ブラウザはほぼ対応
  - 対応していない HTTP クライアントも多い
  - 圧縮レベルによるが、 gzip より圧縮に時間がかかりがち

---

- バッファリング
- 遅いクライアントがいても APP サーバの処理がブロックされない
- 何が嬉しいのかよくわからん

---

- nginx のデフォルトはアップストリームサーバとのコネクションを都度切るようにしている
- コネクションを使い回せる (キープアライブ)
  - HTTP/1.1 を利用する
  - Connection ヘッダに空文字を指定する
- キープアライブを利用すると、接続処理を減らせる
  - 大量のリクエストを受け付けるサーバの場合、コネクションを頻繁に作り直すとパフォーマンスが落ちたり、負荷が上がって適切に動かないことがある
  - ↑ こういった問題に気づくために (9-8 を参照)
    - ss コマンドで Linux 上で利用しているネットワークやソケット情報を収集し、グラフ化する
    - TCP の様々な状態のコネクション数の変動を見る
    - nginx のエラーログを見る。upstream の接続に失敗したエラーが出る

```conf
location / {
  proxy_http_version 1.1;
  proxy_set_header Connection "";
  proxy_pass http://app;
}

upstream app {
  server localhost:8080;

  # キープアライブするコネクションを指定
  keepalive 32;

  # コネクションを閉じるまで受け付ける最大のリクエスト数
  keepalive_requests 10000;
}
```

---

- TLS が有効化されていないとブラウザは HTTP/2 を使わない → 実質的に必須
- HTTP/2 はパフォーマンス上有利なことが多い
- listen 443 ssl http2 のように設定できる
- よくわからん
